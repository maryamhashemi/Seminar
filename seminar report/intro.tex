% !TeX root=main.tex

\pagenumbering{arabic}

\chapter{مقدمه}
%\thispagestyle{empty}
\section{شرح مسئله}
{
در سال‌های اخیر پیشرفت‌های زیادی در مسائل هوش مصنوعی و یادگیری عمیق که در تقاطع دو حوزه پردازش زبان طبیعی  و بینایی ماشین  قرار می‌گیرند؛ رخ داده است. یکی از مسائلی که اخیراً مورد توجه قرارگرفته است؛ پرسش و پاسخ تصویری  است. با توجه به یک تصویر و یک سؤال به زبان طبیعی، سیستم سعی می‌کند با استفاده از عناصر بصری تصویر و استنتاج جمع آوری شده از سوال متنی، پاسخ صحیح را پیدا کند. پرسش و پاسخ تصویری نسخه گسترش یافته مسئله پرسش و پاسخ متنی  است است که اطلاعات بصری به مسئله اضافه شده است. شکل \ref{fig:VQAExample}  گویای تفاوت این دو مسئله است.
	\begin{figure}
		\centerline{
			\includegraphics[scale=0.7]{images/1.JPG}}
		\caption{مثالی از سیستم پرسش و پاسخ متنی و تصویری}
		\label{fig:VQAExample}
	\end{figure}
	
	در سیستم پرسش و پاسخ متنی، یک متن و یک سوال متنی به عنوان ورودی به سیستم داده می‌شود و انتظار می‌رود که سیستم با توجه به درک و تفسیری که از متن و سوال بدست می‌آورد؛ یک جواب متنی را خروجی دهد. اما در سیستم پرسش و پاسخ تصویری، یک تصویر و یک سوال متنی به ورودی سیستم داده می‌شود و انتظار می‌رود که سیستم بتواند با استفاده از عناصر بصری تصویر و تفسیری که از سوال بدست می‌آورد؛ یک پاسخ متنی را در خروجی نشان دهد.
	
	مسئله پرسش و پاسخ تصویری پیچیدگی بیشتری نسبت به مسئله پرسش و پاسخ متنی دارد زیرا تصاویر بعد بالاتر و نویز بیشتری نسبت به متن دارند. علاوه بر این، تصاویر فاقد ساختار و قواعد دستوری زبان هستند. در نهایت هم، تصاویر غنای بیشتری از دنیای واقعی را ضبط می‌کنند، در حالی که زبان طبیعی در حال حاضر نشانگر سطح بالاتری از انتزاع دنیای واقعی است. 
	
}
\section{کاربرد و اهمیت مسئله}
{
در طی سال‌های متمادی، محققان به دنبال ساخت ماشین‌هایی بودند که به اندازه‌ی کافی باهوش باشند که از آن به طور موثر همانند انسان‌ها برای تعامل استفاده کنند. مسئله‌ی پرسش و پاسخ تصویری یکی از پله‌های رسیدن به این رویای هوش مصنوعی است و از این جهت حائز اهمیت است.

کاربردهای بسیاری برای پرسش و پاسخ تصویری وجود دارد. یکی از مهم‌ترین موارد دستیار هوشمند برای افراد کم‌بینا و نابینا  است. علاوه بر این، در سال های اخیر دستیاران صوتی  و عامل‌های گفتگو  مانند  
\lr{Cortana}
،
\lr{Siri}
و
\lr{Alexa}
  در بازار عرضه شدند که می‌توانند با انسان‌ها با استفاده از زبان طبیعی ارتباط برقرار کنند. در حال حاضر این دستیاران با استفاده از صوت و متن این ارتباط را برقرار می‌کنند در نتیجه گفتگوی بین این دستیاران با انسان‌ها مشابه دنیای واقعی نمی‌باشد. این ارتباط را می‌توان با استفاده از داده‌های تصویری و ویدئویی به واقعیت نزدیک‌تر کرد. اینجاست که مسئله‌ی پرسش و پاسخ تصویری برای نزدیک کردن تعامل بین انسان و عامل‌های گفتگو به دنیای واقعی می‌تواند موثر باشد.  همین موضوع را می‌توانیم به صورت گسترده‌تری در ربات‌ها مشاهده کنیم. برای این‌که ربات بتواند بهتر با انسان‌ها ارتباط برقرار کند و به سوالات و درخواست‌ها پاسخ دهد؛ نیاز دارد که درک و فهم درستی از اطراف داشته باشد که این مستلزم داشتن تصویری دقیق از پیرامون است. بنابراین این ربات می‌تواند برای پاسخ به پرسش‌ها از دانشی که از طریق تصویر پیرامون خود بدست می‌آورد، جواب درستی را بدهد.
  
  کاربرد دیگر این مسئله در پزشکی است. در بسیاری از موارد تحلیل تصاویر پزشکی مانند تصاویر CT‌ اسکن و x-ray برای یک پزشک متخصص هم دشوار است. اما یک سیستم پرسش و پاسخ تصویری می‌تواند با تحلیل و تشخیص موارد غیرطبیعی موجود در تصویر، به عنوان نظر دوم به پزشک متخصص کمک کند. از طرفی ممکن است در بعضی اوقات بیمار دسترسی به پزشک را نداشته باشد تا شرح تصاویر را متوجه شود. وجود سیستم پرسش و پاسخ تصویری می‌تواند آگاهی بیمار را نسبت به بیماری افزایش دهد و از نگرانی او بکاهد.
}
\section{بررسی چالشهای موجود در این مسئله}
باید تکمیل شود.
\section{بررسی مجموعه دادگان مطرح و مسابقات مطرح این حوزه}
باید تکمیل شود.
\subsection{مجموعه داده \lr{DAQUAR}}
{
	\textbf{DAQUAR}
	 مخفف
	\lr{Dataset for Question Answering on Real World Images}
است که توسط مالینوفسکی منتشر‌شده‌است. این اولین مجموعه‌داده‌ای است که برای مسئله 
	\lr{VQA}
 منتشر‌شده‌است. تصاویر از مجموعه‌داده
  \lr{NYU-Depth V2}
   گرفته‌شده‌است.  اندازه این مجموعه‌داده کوچک است و در مجموع 1449 تصویر دارد. 
 DAQUAR
 شامل \textit{12468} زوج پرسش و پاسخ با 2483 سوال منحصربه‌فرد است. برای تولید پرسش و پاسخ‌ها از دو روش مصنوعی و انسانی استفاده‌شده‌است. در روش مصنوعی پرسش و پاسخ‌ها به صورت خودکار از الگوهای موجود در جدول فلان تولید‌شده‌است. در روش دیگر از 5 نفر انسان خواسته‌شده‌است تا پرسش و پاسخ تولید کنند. تعداد پرسش و پاسخ‌های آموزشی در این مجموعه‌داده 6794 و تعداد پرسش و پاسخ‌های تست 564 است و به طور میانگین برای هر عکس تقریبا 9 پرسش و پاسخ وجود دارد. این مجموعه‌داده با مشکل بایاس روبه‌رو است زیرا تصاویر این مجموعه تنها مربوط به داخل خانه است و بیش از 400 مورد وجود دارد که اشیایی مثل میز و صندلی در پاسخ‌ها تکرارشده‌است.
}
\subsection{مجموعه داده \lr{VQA}}
{
مجموعه‌داده
 \lr{Visual Question Answering v1(VQA v1)}
یکی از پرکاربردترین مجموعه‌داده‌ها در زمینه پرسش و پاسخ تصویری است. این مجموعه‌داده شامل دو بخش است. یک بخش از تصاویر واقعی ساخته‌شده‌است که
 \lr{VQA-real} 
 نام‌دارد و دیگری با تصاویر کارتونی ساخته‌شده‌است که با نام 
 \lr{VQA-abstract}
 از آن در مقالات یاد می‌شود.
 
 
 \lr{VQA-real} 
 به ترتیب شامل 123287 تصویر آموزشی و 81434 تصویر آزمایشی است که این تصاویر از مجموعه‌داده
 \lr{MS-COCO}
  تهیه شده است.  برای جمع‌آوری پرسش و پاسخ هم از نیروی انسانی استفاده‌شده‌است. برای هر تصویر حداقل 3 سوال منحصربه‌فرد وجود دارد و برای هر سوال 10 پاسخ توسط کاربرهای غیرتکراری جمع‌آوری‌شده‌است. این مجموعه‌داده شامل 614163 سوال به صورت 
  \lr{open-ended}
  و چندگزینه‌ای است. در (اشاره به مقاله) بررسی دقیقی در مورد نوع سوالات، طول سوالات و پاسخ‌ها و غیره انجام‌شده‌است.
  
  
 \lr{VQA-abstract}
 به عنوان یک مجموعه‌داده جداگانه و مکمل در کنار
 \lr{VQA-real}
 قرار دارد. هدف از این مجموعه‌داده از بین بردن نیاز به تجزیه و تحلیل تصاویر واقعی است تا مدل‌ها برای پاسخ به سوالات تمرکز خود را بر روی استدلال‌های سطح بالاتری بگذارند. تصاویر کارتونی در این مجموعه‌داده به صورت دستی توسط انسان‌ها و به وسیله‌ی رابط کاربری که از قبل آماده‌شده‌است؛ ساخته‌شده‌است. تصاویر می‌تواند دو حالت را نشان‌دهند: داخل خانه و خارج از خانه که هر کدام مجموعه متفاوتی از عناصر را شامل می‌شوند از جمله حیوانات، اشیا و انسان‌ها با حالت‌های مختلف. در مجموع 50000 تصویر ایجاد‌شده‌است. مشابه تصاویر واقعی 3 سوال برای هر تصویر (یعنی در کل 150000 سوال) و برای هر سوال 10 پاسخ  جمع‌آوری‌شده‌است.
 
 مجموعه‌داده 
\lr{Visual Question Answering v2(VQA v2)}
در سال 2017 پس از مجموعه‌داده 
\lr{VQA v1}
معرفی شد. 
\lr{VQA v2}
نسبت به 
\lr{VQA v1}
متوازن تر است و تعصبات زبانی در 
\lr{VQA v1}
را کاهش داده است. اندازه‌ی مجموعه داده‌ی
\lr{VQA v2}
تقریبا دو برابر مجموعه‌داده‌ی 
\lr{VQA v1}
است. در مجموعه‌داده‌ی
\lr{VQA v2}
تقریبا برای هر سوال دو تصویر مشابه وجود دارد که پاسخ‌های متفاوتی برای سوال دارند.
}

\subsection{مجموعه داده \lr{Visual Madlibs}}
{
	مجموعه‌داده 
	\lr{Visual Madlibs}
	شکل متفاوتی از پرسش و پاسخ را ارائه می‌دهد. برای هر تصویر جملاتی در نظرگرفته شده‌است و یک کلمه از آن که معمولا مربوط به آدم، اشیا و  فعالیت‌های نمایش‌داده‌شده در تصویر است؛ از جمله حذف‌شده و به جای آن جای‌خالی قرار‌گرفته‌است. پاسخ‌ها کلماتی هستند که این جملات را تکمیل می‌کنند. برای مثال جمله "دو[جای‌خالی]در پارک [جای‌خالی] بازی‌می‌کنند."در وصف یک تصویر بیان‌شده‌است که با دو کلمه "مرد" و "فریزبی" می‌توان جاهای‌خالی‌ را پرکرد. این مجموعه‌داده شامل 10738 تصویر از مجموعه‌داده MS-COCO و 360001 جمله با جای‌خالی است. جملات با جای‌خالی به طور خودکار و با استفاده از الگوهای از پیش‌تعیین‌شده تولیدشده‌اند. پاسخ‌ها در این مجموعه‌داده به هر دو شکل 
	\lr{open-ended}
	و چند‌گزینه‌ای است.
}

\subsection{مجموعه داده \lr{Visual7w}}
{
	مجموعه‌داده
 \lr{Visual7W}
	نیز بر اساس مجموعه‌داده
 \lr{MS-COCO}
	  ساخته‌شده‌است. این مجموعه‌داده شامل 47300 تصویر و 327939 جفت سوال و پاسخ است. این مجموعه‌داده همچنین از 1311756 پرسش و پاسخ چند‌گزینه‌ای تشکیل‌شده‌است که هر سوال 4 گزینه دارد و تنها یکی از گزینه‌ها پاسخ صحیح سوال است. برای جمع‌آوری سوالات چندگزینه‌ای توسط انسان‌ها از پلتفرم آنلاین 
  \lr{Amazon Mechanical Turk}
  استفاده‌شده‌است. نکته‌ی حائز اهمیت در این ‌مجموعه‌داده این است که تمامی اشیایی که در متن پرسش یا پاسخ ذکر‌شده‌است، به نحوی به کادر محدود‌کننده‌ی آن شی در تصویر مرتبط شده‌است. مزیت این روش، رفع ابهام‌های موجود در متن است.  همان‌طور که از نام این مجموعه‌داده پیداست؛ سوالات آن با 7 کلمه‌ی پرسشی که حرف اول آن w است شروع می‌شود. این 7 کلمه شامل
  \lr{what}
  ،
  \lr{where}
  ،
  \lr{when}
  ،
  \lr{who}
  ،
  \lr{why}
  ،
  \lr{how}
  و
  \lr{which}
	است. پرسش‌های
  \lr{Visual7W}
	 نسبت به به مجموعه‌داده 
  \lr{VQA v1}
  غنی‌تر و سخت‌تر است. همچنین پاسخ‌ها طولانی‌تر هستند
}
\subsection{مجموعه داده \lr{CLEVR}}
{
\lr{CLEVR}
 یک مجموعه‌داده برای ارزیابی درک بصری سیستم‌های 
 \lr{VQA}
  است. تصاویر این مجموعه‌داده با استفاده از سه شی استوانه، کره و مکعب تولیدشده‌است. برای هر کدام از این اشیا دو اندازه متفاوت، دو جنس متفاوت و هشت رنگ مختف در نظر گرفته شده است. سوالات هم به طور مصنوعی بر اساس مکانی که اشیا در تصوبر قرار گرفته اند؛ ایجاد شده‌است. سوالات در
   \lr{CLEVR }
   به گونه‌ای طراحی‌شده‌است که جنبه‌های مختلف استدلال بصری توسط سیستم‌های 
   \lr{VQA}
   را مورد ارزیابی قرار می‌دهد از جمله شناسایی ویژگی، شمارش اشیا، مقایسه، روابط مکانی اشیا و عملیات منطقی. در این مجموعه‌داده مکان تصاویر نیز با استفاده از یک مستطیل مشخص‌شده‌است.
}
\subsection{مجموعه داده \lr{Tally-QA}}
{
	در سال 2019، مجموعه‌داده 
   \lr{Tally-QA}
منتشر شد که بزرگ‌ترین مجموعه‌داده شمارش اشیا است. این مجموعه داده 5.2 برابر مجموعه‌داده
\lr{VQA v1}
 است. 
 \lr{Tally-QA}
 شامل 287907 سوال، 165000 تصویر و 19000 سوال پیچیده است. }
\subsection{مجموعه داده \lr{KVQA}}
{
برای رسیدن به پاسخ سوالات موجود در این مجموعه‌داده، نیاز به استدلال‌های چند جانبه است. این مجموعه داده شامل 24000 تصویر و 183100 پرسش و پاسخ است.
}
\section{بررسی فازهای مختلف مسئله پرسش و پاسخ تصویری}
باید تکمیل شود.
\subsection{فاز 1 : استخراج ویژگی از تصویر و سوا ل}
باید تکمیل شود.
\subsection{فاز 2 : درک مشترک تصویر و سوا ل}
باید تکمیل شود.
\subsection{فاز 3 : تولید جواب}
باید تکمیل شود.
\section{معیارهای ارزیابی مسئله پرسش و پاسخ تصویری}
باید تکمیل شود.
\section{ چگونگی ساخت مجموعه داده حاوی پرسش و پاسخ به زبان فارسی}
باید تکمیل شود.