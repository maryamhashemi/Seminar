@inproceedings{goyal2017making,
	title={Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering},
	author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={6904--6913},
	year={2017}
}

@inproceedings{antol2015vqa,
	title={Vqa: Visual question answering},
	author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Lawrence Zitnick, C and Parikh, Devi},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={2425--2433},
	year={2015}
}

@inproceedings{malinowski2014multi,
	title={A multi-world approach to question answering about real-world scenes based on uncertain input},
	author={Malinowski, Mateusz and Fritz, Mario},
	booktitle={Advances in neural information processing systems},
	pages={1682--1690},
	year={2014}
}

@inproceedings{yu2015visual,
	title={Visual madlibs: Fill in the blank description generation and question answering},
	author={Yu, Licheng and Park, Eunbyung and Berg, Alexander C and Berg, Tamara L},
	booktitle={Proceedings of the ieee international conference on computer vision},
	pages={2461--2469},
	year={2015}
}

@inproceedings{zhu2016visual7w,
	title={Visual7w: Grounded question answering in images},
	author={Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4995--5004},
	year={2016}
}

@inproceedings{johnson2017clevr,
	title={Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
	author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={2901--2910},
	year={2017}
}

@inproceedings{acharya2019tallyqa,
	title={TallyQA: Answering complex counting questions},
	author={Acharya, Manoj and Kafle, Kushal and Kanan, Christopher},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={33},
	pages={8076--8084},
	year={2019}
}

@inproceedings{shah2019kvqa,
	title={Kvqa: Knowledge-aware visual question answering},
	author={Shah, Sanket and Mishra, Anand and Yadati, Naganand and Talukdar, Partha Pratim},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={33},
	pages={8876--8884},
	year={2019}
}

@inproceedings{papineni2002bleu,
	title={BLEU: a method for automatic evaluation of machine translation},
	author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
	booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
	pages={311--318},
	year={2002}
}

@inproceedings{denkowski2014meteor,
	title={Meteor universal: Language specific translation evaluation for any target language},
	author={Denkowski, Michael and Lavie, Alon},
	booktitle={Proceedings of the ninth workshop on statistical machine translation},
	pages={376--380},
	year={2014}
}

@inproceedings{kafle2017analysis,
	title={An analysis of visual question answering algorithms},
	author={Kafle, Kushal and Kanan, Christopher},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={1965--1973},
	year={2017}
}

@article{wu1994verb,
	title={Verb semantics and lexical selection},
	author={Wu, Zhibiao and Palmer, Martha},
	journal={arXiv preprint cmp-lg/9406033},
	year={1994}
}

@article{toor2019question,
	title={Question action relevance and editing for visual question answering},
	author={Toor, Andeep S and Wechsler, Harry and Nappi, Michele},
	journal={Multimedia Tools and Applications},
	volume={78},
	number={3},
	pages={2921--2935},
	year={2019},
	publisher={Springer}
}

@article{peng2019word,
	title={Word-to-region attention network for visual question answering},
	author={Peng, Liang and Yang, Yang and Bin, Yi and Xie, Ning and Shen, Fumin and Ji, Yanli and Xu, Xing},
	journal={Multimedia Tools and Applications},
	volume={78},
	number={3},
	pages={3843--3858},
	year={2019},
	publisher={Springer}
}

@inproceedings{cao2017jointly,
	title={Jointly learning attentions with semantic cross-modal correlation for visual question answering},
	author={Cao, Liangfu and Gao, Lianli and Song, Jingkuan and Xu, Xing and Shen, Heng Tao},
	booktitle={Australasian Database Conference},
	pages={248--260},
	year={2017},
	organization={Springer}
}

@inproceedings{cao2017jointly,
	title={Jointly learning attentions with semantic cross-modal correlation for visual question answering},
	author={Cao, Liangfu and Gao, Lianli and Song, Jingkuan and Xu, Xing and Shen, Heng Tao},
	booktitle={Australasian Database Conference},
	pages={248--260},
	year={2017},
	organization={Springer}
}

@inproceedings{bai2018deep,
	title={Deep attention neural tensor network for visual question answering},
	author={Bai, Yalong and Fu, Jianlong and Zhao, Tiejun and Mei, Tao},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={20--35},
	year={2018}
}

@inproceedings{teney2018visual,
	title={Visual question answering as a meta learning task},
	author={Teney, Damien and van den Hengel, Anton},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={219--235},
	year={2018}
}

@article{lioutas2018explicit,
	title={Explicit ensemble attention learning for improving visual question answering},
	author={Lioutas, Vasileios and Passalis, Nikolaos and Tefas, Anastasios},
	journal={Pattern Recognition Letters},
	volume={111},
	pages={51--57},
	year={2018},
	publisher={Elsevier}
}

@article{lao2018cross,
	title={Cross-modal multistep fusion network with co-attention for visual question answering},
	author={Lao, Mingrui and Guo, Yanming and Wang, Hui and Zhang, Xin},
	journal={IEEE Access},
	volume={6},
	pages={31516--31524},
	year={2018},
	publisher={IEEE}
}

@inproceedings{ruwa2018affective,
	title={Affective visual question answering network},
	author={Ruwa, Nelson and Mao, Qirong and Wang, Liangjun and Dong, Ming},
	booktitle={2018 IEEE conference on multimedia information processing and retrieval (MIPR)},
	pages={170--173},
	year={2018},
	organization={IEEE}
}

@article{yu2018beyond,
	title={Beyond bilinear: Generalized multimodal factorized high-order pooling for visual question answering},
	author={Yu, Zhou and Yu, Jun and Xiang, Chenchao and Fan, Jianping and Tao, Dacheng},
	journal={IEEE transactions on neural networks and learning systems},
	volume={29},
	number={12},
	pages={5947--5959},
	year={2018},
	publisher={IEEE}
}

@inproceedings{malinowski2018learning,
	title={Learning visual question answering by bootstrapping hard attention},
	author={Malinowski, Mateusz and Doersch, Carl and Santoro, Adam and Battaglia, Peter},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={3--20},
	year={2018}
}

@inproceedings{cao2017jointly,
	title={Jointly learning attentions with semantic cross-modal correlation for visual question answering},
	author={Cao, Liangfu and Gao, Lianli and Song, Jingkuan and Xu, Xing and Shen, Heng Tao},
	booktitle={Australasian Database Conference},
	pages={248--260},
	year={2017},
	organization={Springer}
}

@article{malinowski2017ask,
	title={Ask your neurons: A deep learning approach to visual question answering},
	author={Malinowski, Mateusz and Rohrbach, Marcus and Fritz, Mario},
	journal={International Journal of Computer Vision},
	volume={125},
	number={1-3},
	pages={110--135},
	year={2017},
	publisher={Springer}
}

@inproceedings{shih2016look,
	title={Where to look: Focus regions for visual question answering},
	author={Shih, Kevin J and Singh, Saurabh and Hoiem, Derek},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4613--4621},
	year={2016}
}

@inproceedings{xu2016ask,
	title={Ask, attend and answer: Exploring question-guided spatial attention for visual question answering},
	author={Xu, Huijuan and Saenko, Kate},
	booktitle={European Conference on Computer Vision},
	pages={451--466},
	year={2016},
	organization={Springer}
}

@article{fukui2016multimodal,
	title={Multimodal compact bilinear pooling for visual question answering and visual grounding},
	author={Fukui, Akira and Park, Dong Huk and Yang, Daylen and Rohrbach, Anna and Darrell, Trevor and Rohrbach, Marcus},
	journal={arXiv preprint arXiv:1606.01847},
	year={2016}
}

@inproceedings{jabri2016revisiting,
	title={Revisiting visual question answering baselines},
	author={Jabri, Allan and Joulin, Armand and Van Der Maaten, Laurens},
	booktitle={European conference on computer vision},
	pages={727--739},
	year={2016},
	organization={Springer}
}

@inproceedings{lin2016leveraging,
	title={Leveraging visual question answering for image-caption ranking},
	author={Lin, Xiao and Parikh, Devi},
	booktitle={European Conference on Computer Vision},
	pages={261--277},
	year={2016},
	organization={Springer}
}

@inproceedings{Ma2016LearningTA,
	title={Learning to Answer Questions from Image Using Convolutional Neural Network},
	author={L. Ma and Z. Lu and Hang Li},
	booktitle={AAAI},
	year={2016}
}

@inproceedings{noh2016image,
	title={Image question answering using convolutional neural network with dynamic parameter prediction},
	author={Noh, Hyeonwoo and Hongsuck Seo, Paul and Han, Bohyung},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={30--38},
	year={2016}
}

@article{andreas2015deep,
	title={Deep compositional question answering with neural module networks. CoRR abs/1511.02799 (2015)},
	author={Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
	journal={arXiv preprint arXiv:1511.02799},
	year={2015}
}

@article{chen2015abc,
	title={Abc-cnn: An attention based convolutional neural network for visual question answering},
	author={Chen, Kan and Wang, Jiang and Chen, Liang-Chieh and Gao, Haoyuan and Xu, Wei and Nevatia, Ram},
	journal={arXiv preprint arXiv:1511.05960},
	year={2015}
}

@inproceedings{ren2015exploring,
	title={Exploring models and data for image question answering},
	author={Ren, Mengye and Kiros, Ryan and Zemel, Richard},
	booktitle={Advances in neural information processing systems},
	pages={2953--2961},
	year={2015}
}

@inproceedings{gao2015you,
	title={Are you talking to a machine? dataset and methods for multilingual image question},
	author={Gao, Haoyuan and Mao, Junhua and Zhou, Jie and Huang, Zhiheng and Wang, Lei and Xu, Wei},
	booktitle={Advances in neural information processing systems},
	pages={2296--2304},
	year={2015}
}

@article{ren2015image,
	title={Image question answering: A visual semantic embedding model and a new dataset},
	author={Ren, Mengye and Kiros, Ryan and Zemel, Richard},
	journal={Proc. Advances in Neural Inf. Process. Syst},
	volume={1},
	number={2},
	pages={5},
	year={2015}
}

@article{wang2015explicit,
	title={Explicit knowledge-based reasoning for visual question answering},
	author={Wang, Peng and Wu, Qi and Shen, Chunhua and Hengel, Anton van den and Dick, Anthony},
	journal={arXiv preprint arXiv:1511.02570},
	year={2015}
}

@inproceedings{shi2018question,
	title={Question type guided attention in visual question answering},
	author={Shi, Yang and Furlanello, Tommaso and Zha, Sheng and Anandkumar, Animashree},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={151--166},
	year={2018}
}

@article{hinton2012imagenet,
	title={Imagenet classification with deep convolutional neural networks},
	author={Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya},
	journal={Advances in neural information processing systems},
	volume={25},
	pages={1106--1114},
	year={2012}
}

@article{simonyan2014very,
	title={Very deep convolutional networks for large-scale image recognition},
	author={Simonyan, Karen and Zisserman, Andrew},
	journal={arXiv preprint arXiv:1409.1556},
	year={2014}
}

@inproceedings{szegedy2015going,
	title={Going deeper with convolutions},
	author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={1--9},
	year={2015}
}

@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}

@article{manmadhan2020visual,
	title={Visual question answering: a state-of-the-art review},
	author={Manmadhan, Sruthy and Kovoor, Binsu C},
	journal={Artificial Intelligence Review},
	pages={1--41},
	year={2020},
	publisher={Springer}
}

@article{wu2017visual,
	title={Visual question answering: A survey of methods and datasets},
	author={Wu, Qi and Teney, Damien and Wang, Peng and Shen, Chunhua and Dick, Anthony and van den Hengel, Anton},
	journal={Computer Vision and Image Understanding},
	volume={163},
	pages={21--40},
	year={2017},
	publisher={Elsevier}
}

@inproceedings{gurari2018vizwiz,
	title={Vizwiz grand challenge: Answering visual questions from blind people},
	author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={3608--3617},
	year={2018}
}