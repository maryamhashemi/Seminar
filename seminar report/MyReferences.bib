@inproceedings{goyal2017making,
	title={Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering},
	author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={6904--6913},
	year={2017}
}

@inproceedings{antol2015vqa,
	title={Vqa: Visual question answering},
	author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Lawrence Zitnick, C and Parikh, Devi},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={2425--2433},
	year={2015}
}

@inproceedings{malinowski2014multi,
	title={A multi-world approach to question answering about real-world scenes based on uncertain input},
	author={Malinowski, Mateusz and Fritz, Mario},
	booktitle={Advances in neural information processing systems},
	pages={1682--1690},
	year={2014}
}

@inproceedings{yu2015visual,
	title={Visual madlibs: Fill in the blank description generation and question answering},
	author={Yu, Licheng and Park, Eunbyung and Berg, Alexander C and Berg, Tamara L},
	booktitle={Proceedings of the ieee international conference on computer vision},
	pages={2461--2469},
	year={2015}
}

@inproceedings{zhu2016visual7w,
	title={Visual7w: Grounded question answering in images},
	author={Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4995--5004},
	year={2016}
}

@inproceedings{johnson2017clevr,
	title={Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
	author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={2901--2910},
	year={2017}
}

@inproceedings{acharya2019tallyqa,
	title={TallyQA: Answering complex counting questions},
	author={Acharya, Manoj and Kafle, Kushal and Kanan, Christopher},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={33},
	pages={8076--8084},
	year={2019}
}

@inproceedings{shah2019kvqa,
	title={Kvqa: Knowledge-aware visual question answering},
	author={Shah, Sanket and Mishra, Anand and Yadati, Naganand and Talukdar, Partha Pratim},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={33},
	pages={8876--8884},
	year={2019}
}

@inproceedings{papineni2002bleu,
	title={BLEU: a method for automatic evaluation of machine translation},
	author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
	booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
	pages={311--318},
	year={2002}
}

@inproceedings{denkowski2014meteor,
	title={Meteor universal: Language specific translation evaluation for any target language},
	author={Denkowski, Michael and Lavie, Alon},
	booktitle={Proceedings of the ninth workshop on statistical machine translation},
	pages={376--380},
	year={2014}
}

@inproceedings{kafle2017analysis,
	title={An analysis of visual question answering algorithms},
	author={Kafle, Kushal and Kanan, Christopher},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={1965--1973},
	year={2017}
}

@article{wu1994verb,
	title={Verb semantics and lexical selection},
	author={Wu, Zhibiao and Palmer, Martha},
	journal={arXiv preprint cmp-lg/9406033},
	year={1994}
}

@article{toor2019question,
	title={Question action relevance and editing for visual question answering},
	author={Toor, Andeep S and Wechsler, Harry and Nappi, Michele},
	journal={Multimedia Tools and Applications},
	volume={78},
	number={3},
	pages={2921--2935},
	year={2019},
	publisher={Springer}
}

@article{peng2019word,
	title={Word-to-region attention network for visual question answering},
	author={Peng, Liang and Yang, Yang and Bin, Yi and Xie, Ning and Shen, Fumin and Ji, Yanli and Xu, Xing},
	journal={Multimedia Tools and Applications},
	volume={78},
	number={3},
	pages={3843--3858},
	year={2019},
	publisher={Springer}
}

@inproceedings{cao2017jointly,
	title={Jointly learning attentions with semantic cross-modal correlation for visual question answering},
	author={Cao, Liangfu and Gao, Lianli and Song, Jingkuan and Xu, Xing and Shen, Heng Tao},
	booktitle={Australasian Database Conference},
	pages={248--260},
	year={2017},
	organization={Springer}
}

@inproceedings{cao2017jointly,
	title={Jointly learning attentions with semantic cross-modal correlation for visual question answering},
	author={Cao, Liangfu and Gao, Lianli and Song, Jingkuan and Xu, Xing and Shen, Heng Tao},
	booktitle={Australasian Database Conference},
	pages={248--260},
	year={2017},
	organization={Springer}
}

@inproceedings{bai2018deep,
	title={Deep attention neural tensor network for visual question answering},
	author={Bai, Yalong and Fu, Jianlong and Zhao, Tiejun and Mei, Tao},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={20--35},
	year={2018}
}

@inproceedings{teney2018visual,
	title={Visual question answering as a meta learning task},
	author={Teney, Damien and van den Hengel, Anton},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={219--235},
	year={2018}
}

@article{lioutas2018explicit,
	title={Explicit ensemble attention learning for improving visual question answering},
	author={Lioutas, Vasileios and Passalis, Nikolaos and Tefas, Anastasios},
	journal={Pattern Recognition Letters},
	volume={111},
	pages={51--57},
	year={2018},
	publisher={Elsevier}
}

@article{lao2018cross,
	title={Cross-modal multistep fusion network with co-attention for visual question answering},
	author={Lao, Mingrui and Guo, Yanming and Wang, Hui and Zhang, Xin},
	journal={IEEE Access},
	volume={6},
	pages={31516--31524},
	year={2018},
	publisher={IEEE}
}

@inproceedings{ruwa2018affective,
	title={Affective visual question answering network},
	author={Ruwa, Nelson and Mao, Qirong and Wang, Liangjun and Dong, Ming},
	booktitle={2018 IEEE conference on multimedia information processing and retrieval (MIPR)},
	pages={170--173},
	year={2018},
	organization={IEEE}
}

@article{yu2018beyond,
	title={Beyond bilinear: Generalized multimodal factorized high-order pooling for visual question answering},
	author={Yu, Zhou and Yu, Jun and Xiang, Chenchao and Fan, Jianping and Tao, Dacheng},
	journal={IEEE transactions on neural networks and learning systems},
	volume={29},
	number={12},
	pages={5947--5959},
	year={2018},
	publisher={IEEE}
}

@inproceedings{malinowski2018learning,
	title={Learning visual question answering by bootstrapping hard attention},
	author={Malinowski, Mateusz and Doersch, Carl and Santoro, Adam and Battaglia, Peter},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={3--20},
	year={2018}
}

@inproceedings{cao2017jointly,
	title={Jointly learning attentions with semantic cross-modal correlation for visual question answering},
	author={Cao, Liangfu and Gao, Lianli and Song, Jingkuan and Xu, Xing and Shen, Heng Tao},
	booktitle={Australasian Database Conference},
	pages={248--260},
	year={2017},
	organization={Springer}
}

@article{malinowski2017ask,
	title={Ask your neurons: A deep learning approach to visual question answering},
	author={Malinowski, Mateusz and Rohrbach, Marcus and Fritz, Mario},
	journal={International Journal of Computer Vision},
	volume={125},
	number={1-3},
	pages={110--135},
	year={2017},
	publisher={Springer}
}

@inproceedings{shih2016look,
	title={Where to look: Focus regions for visual question answering},
	author={Shih, Kevin J and Singh, Saurabh and Hoiem, Derek},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4613--4621},
	year={2016}
}

@inproceedings{xu2016ask,
	title={Ask, attend and answer: Exploring question-guided spatial attention for visual question answering},
	author={Xu, Huijuan and Saenko, Kate},
	booktitle={European Conference on Computer Vision},
	pages={451--466},
	year={2016},
	organization={Springer}
}

@article{fukui2016multimodal,
	title={Multimodal compact bilinear pooling for visual question answering and visual grounding},
	author={Fukui, Akira and Park, Dong Huk and Yang, Daylen and Rohrbach, Anna and Darrell, Trevor and Rohrbach, Marcus},
	journal={arXiv preprint arXiv:1606.01847},
	year={2016}
}

@inproceedings{jabri2016revisiting,
	title={Revisiting visual question answering baselines},
	author={Jabri, Allan and Joulin, Armand and Van Der Maaten, Laurens},
	booktitle={European conference on computer vision},
	pages={727--739},
	year={2016},
	organization={Springer}
}

@inproceedings{lin2016leveraging,
	title={Leveraging visual question answering for image-caption ranking},
	author={Lin, Xiao and Parikh, Devi},
	booktitle={European Conference on Computer Vision},
	pages={261--277},
	year={2016},
	organization={Springer}
}

@inproceedings{Ma2016LearningTA,
	title={Learning to Answer Questions from Image Using Convolutional Neural Network},
	author={L. Ma and Z. Lu and Hang Li},
	booktitle={AAAI},
	year={2016}
}

@inproceedings{noh2016image,
	title={Image question answering using convolutional neural network with dynamic parameter prediction},
	author={Noh, Hyeonwoo and Hongsuck Seo, Paul and Han, Bohyung},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={30--38},
	year={2016}
}

@article{andreas2015deep,
	title={Deep compositional question answering with neural module networks. CoRR abs/1511.02799 (2015)},
	author={Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
	journal={arXiv preprint arXiv:1511.02799},
	year={2015}
}

@article{chen2015abc,
	title={Abc-cnn: An attention based convolutional neural network for visual question answering},
	author={Chen, Kan and Wang, Jiang and Chen, Liang-Chieh and Gao, Haoyuan and Xu, Wei and Nevatia, Ram},
	journal={arXiv preprint arXiv:1511.05960},
	year={2015}
}

@inproceedings{ren2015exploring,
	title={Exploring models and data for image question answering},
	author={Ren, Mengye and Kiros, Ryan and Zemel, Richard},
	booktitle={Advances in neural information processing systems},
	pages={2953--2961},
	year={2015}
}

@inproceedings{gao2015you,
	title={Are you talking to a machine? dataset and methods for multilingual image question},
	author={Gao, Haoyuan and Mao, Junhua and Zhou, Jie and Huang, Zhiheng and Wang, Lei and Xu, Wei},
	booktitle={Advances in neural information processing systems},
	pages={2296--2304},
	year={2015}
}

@article{ren2015image,
	title={Image question answering: A visual semantic embedding model and a new dataset},
	author={Ren, Mengye and Kiros, Ryan and Zemel, Richard},
	journal={Proc. Advances in Neural Inf. Process. Syst},
	volume={1},
	number={2},
	pages={5},
	year={2015}
}

@article{wang2015explicit,
	title={Explicit knowledge-based reasoning for visual question answering},
	author={Wang, Peng and Wu, Qi and Shen, Chunhua and Hengel, Anton van den and Dick, Anthony},
	journal={arXiv preprint arXiv:1511.02570},
	year={2015}
}

@inproceedings{shi2018question,
	title={Question type guided attention in visual question answering},
	author={Shi, Yang and Furlanello, Tommaso and Zha, Sheng and Anandkumar, Animashree},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={151--166},
	year={2018}
}

@article{hinton2012imagenet,
	title={Imagenet classification with deep convolutional neural networks},
	author={Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya},
	journal={Advances in neural information processing systems},
	volume={25},
	pages={1106--1114},
	year={2012}
}

@article{simonyan2014very,
	title={Very deep convolutional networks for large-scale image recognition},
	author={Simonyan, Karen and Zisserman, Andrew},
	journal={arXiv preprint arXiv:1409.1556},
	year={2014}
}

@inproceedings{szegedy2015going,
	title={Going deeper with convolutions},
	author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={1--9},
	year={2015}
}

@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}

@article{manmadhan2020visual,
	title={Visual question answering: a state-of-the-art review},
	author={Manmadhan, Sruthy and Kovoor, Binsu C},
	journal={Artificial Intelligence Review},
	pages={1--41},
	year={2020},
	publisher={Springer}
}

@article{wu2017visual,
	title={Visual question answering: A survey of methods and datasets},
	author={Wu, Qi and Teney, Damien and Wang, Peng and Shen, Chunhua and Dick, Anthony and van den Hengel, Anton},
	journal={Computer Vision and Image Understanding},
	volume={163},
	pages={21--40},
	year={2017},
	publisher={Elsevier}
}

@inproceedings{gurari2018vizwiz,
	title={Vizwiz grand challenge: Answering visual questions from blind people},
	author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={3608--3617},
	year={2018}
}

@inproceedings{talafha2018just,
	title={JUST at VQA-Med: A VGG-Seq2Seq Model.},
	author={Talafha, Bashar and Al-Ayyoub, Mahmoud},
	booktitle={CLEF (Working Notes)},
	year={2018}
}

@inproceedings{silberman2012indoor,
	title={Indoor segmentation and support inference from rgbd images},
	author={Silberman, Nathan and Hoiem, Derek and Kohli, Pushmeet and Fergus, Rob},
	booktitle={European conference on computer vision},
	pages={746--760},
	year={2012},
	organization={Springer}
}

@inproceedings{lin2014microsoft,
	title={Microsoft coco: Common objects in context},
	author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
	booktitle={European conference on computer vision},
	pages={740--755},
	year={2014},
	organization={Springer}
}

@article{krishna2017visual,
	title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
	author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
	journal={International journal of computer vision},
	volume={123},
	number={1},
	pages={32--73},
	year={2017},
	publisher={Springer}
}

@inproceedings{deng2009imagenet,
	title={Imagenet: A large-scale hierarchical image database},
	author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	booktitle={2009 IEEE conference on computer vision and pattern recognition},
	pages={248--255},
	year={2009},
	organization={Ieee}
}

@article{mikolov2013efficient,
	title={Efficient estimation of word representations in vector space},
	author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	journal={arXiv preprint arXiv:1301.3781},
	year={2013}
}

@inproceedings{pennington2014glove,
	title={Glove: Global vectors for word representation},
	author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
	booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
	pages={1532--1543},
	year={2014}
}

@article{hochreiter1997long,
	title={Long short-term memory},
	author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	journal={Neural computation},
	volume={9},
	number={8},
	pages={1735--1780},
	year={1997},
	publisher={MIT Press}
}

@article{cho2014learning,
	title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
	author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	journal={arXiv preprint arXiv:1406.1078},
	year={2014}
}

@article{gong2014multi,
	title={A multi-view embedding space for modeling internet images, tags, and their semantics},
	author={Gong, Yunchao and Ke, Qifa and Isard, Michael and Lazebnik, Svetlana},
	journal={International journal of computer vision},
	volume={106},
	number={2},
	pages={210--233},
	year={2014},
	publisher={Springer}
}

@article{tommasi2019combining,
	title={Combining multiple cues for visual madlibs question answering},
	author={Tommasi, Tatiana and Mallya, Arun and Plummer, Bryan and Lazebnik, Svetlana and Berg, Alexander C and Berg, Tamara L},
	journal={International Journal of Computer Vision},
	volume={127},
	number={1},
	pages={38--60},
	year={2019},
	publisher={Springer}
}

@inproceedings{kafle2017data,
	title={Data augmentation for visual question answering},
	author={Kafle, Kushal and Yousefhussien, Mohammed and Kanan, Christopher},
	booktitle={Proceedings of the 10th International Conference on Natural Language Generation},
	pages={198--202},
	year={2017}
}

@inproceedings{kafle2016answer,
	title={Answer-type prediction for visual question answering},
	author={Kafle, Kushal and Kanan, Christopher},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={4976--4984},
	year={2016}
}

@inproceedings{tang2020semantic,
	title={Semantic equivalent adversarial data augmentation for visual question answering},
	author={Tang, Ruixue and Ma, Chao and Zhang, Wei Emma and Wu, Qi and Yang, Xiaokang},
	booktitle={European Conference on Computer Vision},
	pages={437--453},
	year={2020},
	organization={Springer}
}

@article{devlin2018bert,
	title={Bert: Pre-training of deep bidirectional transformers for language understanding},
	author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	journal={arXiv preprint arXiv:1810.04805},
	year={2018}
}

@article{radford2019language,
	title={Language models are unsupervised multitask learners},
	author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	journal={OpenAI blog},
	volume={1},
	number={8},
	pages={9},
	year={2019}
}

@article{brown2020language,
	title={Language models are few-shot learners},
	author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	journal={arXiv preprint arXiv:2005.14165},
	year={2020}
}

@inproceedings{sun2019videobert,
	title={Videobert: A joint model for video and language representation learning},
	author={Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={7464--7473},
	year={2019}
}

@article{alberti2019fusion,
	title={Fusion of detected objects in text for visual question answering},
	author={Alberti, Chris and Ling, Jeffrey and Collins, Michael and Reitter, David},
	journal={arXiv preprint arXiv:1908.05054},
	year={2019}
}

@inproceedings{li2020unicoder,
	title={Unicoder-VL: A Universal Encoder for Vision and Language by Cross-Modal Pre-Training.},
	author={Li, Gen and Duan, Nan and Fang, Yuejian and Gong, Ming and Jiang, Daxin and Zhou, Ming},
	booktitle={AAAI},
	pages={11336--11344},
	year={2020}
}

@article{su2019vl,
	title={Vl-bert: Pre-training of generic visual-linguistic representations},
	author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
	journal={arXiv preprint arXiv:1908.08530},
	year={2019}
}

@inproceedings{chen2020uniter,
	title={Uniter: Universal image-text representation learning},
	author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
	booktitle={European Conference on Computer Vision},
	pages={104--120},
	year={2020},
	organization={Springer}
}

@inproceedings{zhou2020unified,
	title={Unified Vision-Language Pre-Training for Image Captioning and VQA.},
	author={Zhou, Luowei and Palangi, Hamid and Zhang, Lei and Hu, Houdong and Corso, Jason J and Gao, Jianfeng},
	booktitle={AAAI},
	pages={13041--13049},
	year={2020}
}

@inproceedings{li2020oscar,
	title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
	author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
	booktitle={European Conference on Computer Vision},
	pages={121--137},
	year={2020},
	organization={Springer}
}

@inproceedings{lu2019vilbert,
	title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
	author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
	booktitle={Advances in Neural Information Processing Systems},
	pages={13--23},
	year={2019}
}

@article{tan2019lxmert,
	title={Lxmert: Learning cross-modality encoder representations from transformers},
	author={Tan, Hao and Bansal, Mohit},
	journal={arXiv preprint arXiv:1908.07490},
	year={2019}
}